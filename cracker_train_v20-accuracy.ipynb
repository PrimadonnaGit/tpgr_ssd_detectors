{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version20 : Focal-CTC-Loss(0.75,0.5) + lstm-dropout(0.1,0.1)  + LeakyReLU(0.05) + augement + Adam(0.001,1e-3) + Freeze(1~4) + data_merge(1560) + batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41493\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:768: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import editdistance\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from crnn_model_focal_ctc_loss import CRNN\n",
    "from crnn_data_focal_ctc_loss import InputGenerator\n",
    "from crnn_utils import decode\n",
    "from utils.training import Logger, ModelSnapshot\n",
    "from cracker_util import cracker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic Eco\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "#matplotlib 한글 폰트 설정\n",
    "\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'\n",
    "font_name = fm.FontProperties(fname=path, size=16).get_name()\n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cracker import GTUtility\n",
    "\n",
    "file_name = 'gt_util_merge_data.pkl'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    gt_util_cracker = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_util_train, gt_util_val = GTUtility.randomSplit(gt_util_cracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520\n",
      "1216\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "print(len(gt_util_cracker.image_names))\n",
    "print(len(gt_util_train.image_names))\n",
    "print(len(gt_util_val.image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "836\n"
     ]
    }
   ],
   "source": [
    "from cracker_util import cracker_dict\n",
    "from crnn_utils import alphabet87\n",
    "print(len(alphabet87))\n",
    "print(len(cracker_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 256\n",
    "input_height = 32\n",
    "batch_size = 32\n",
    "input_shape = (input_width, input_height, 1)\n",
    "max_string_len = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'crnn_ksignboard_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---predict---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model, model_pred = CRNN(input_shape, len(cracker_dict), gru=False, alpha=0.75,gamma=0.5)\n",
    "max_string_len = model_pred.output_shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---training---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ina/anaconda3/envs/ina/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "alpha=0.75\n",
    "gamma=0.5\n",
    "\n",
    "model, model_pred = CRNN(input_shape, len(cracker_dict), gru=False, alpha=alpha,gamma=gamma)\n",
    "model_trained,_ = CRNN(input_shape, len(alphabet87), gru=False, alpha=alpha,gamma=gamma)\n",
    "\n",
    "model_trained.load_weights('weights.h5')\n",
    "\n",
    "max_string_len = model_pred.output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(16):\n",
    "    extracted_weights = model_trained.layers[idx].get_weights()\n",
    "    model.layers[idx].set_weights(extracted_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze = ['conv1_1',\n",
    "          'conv2_1',\n",
    "          'conv3_1', 'conv3_2', \n",
    "          'conv4_1',\n",
    "          #'conv5_1',\n",
    "          #'conv6_1',\n",
    "          #'lstm1',\n",
    "          #'lstm2'\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train = InputGenerator(gt_util_train, batch_size, cracker_dict, input_shape[:2], \n",
    "                           grayscale=True, max_string_len=max_string_len)\n",
    "gen_val = InputGenerator(gt_util_val, batch_size, cracker_dict, input_shape[:2], \n",
    "                         grayscale=True, max_string_len=max_string_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdir = './checkpoints/' + time.strftime('%Y%m%d%H%M') + '_' + experiment\n",
    "if not os.path.exists(checkdir):\n",
    "    os.makedirs(checkdir)\n",
    "\n",
    "with open(checkdir+'/source.py','wb') as f:\n",
    "    source = ''.join(['# In[%i]\\n%s\\n\\n' % (i, In[i]) for i in range(len(In))])\n",
    "    f.write(source.encode())\n",
    "    \n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=32, \n",
    "                                          write_graph=True, write_grads=False, write_images=False, \n",
    "                                          embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, \n",
    "                                          embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "# tensorboard --logdir=./logs\n",
    "\n",
    "# livelossplot\n",
    "\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "\n",
    "#EarlyStopping\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred.load_weights('./checkpoints/201904301143_crnn_ksignboard_v20/weights.057.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_val.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]['source_str'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = model_pred.predict(d[0]['image_input'])\n",
    "\n",
    "mean_ed = 0\n",
    "mean_ed_norm = 0\n",
    "\n",
    "plot_name = 'crnn_ksignboard'\n",
    "\n",
    "#for i in range(len(res)):\n",
    "all_total_length = 0\n",
    "all_score = 0\n",
    "for i in range(32):\n",
    "    \n",
    "    # best path, real ocr applications use beam search with dictionary and language model\n",
    "    chars = [cracker_dict[c] for c in np.argmax(res[i], axis=1)]\n",
    "    gt_str = d[0]['source_str'][i]\n",
    "    res_str = decode(chars)\n",
    "    \n",
    "    ed = editdistance.eval(gt_str, res_str)\n",
    "    #ed = levenshtein(gt_str, res_str)\n",
    "    ed_norm = ed / len(gt_str)\n",
    "    mean_ed += ed\n",
    "    mean_ed_norm += ed_norm\n",
    "    \n",
    "    g = list(gt_str)\n",
    "    r = list(res_str)\n",
    "    score = 0\n",
    "    if len(g) == len(r):\n",
    "        total_len = len(g)   \n",
    "        for idx in range(total_len):\n",
    "            if g[idx] == r[idx]:\n",
    "                score += 1\n",
    "        \n",
    "        acc = (score / total_len ) * 100\n",
    "        all_score += score\n",
    "        all_total_length += total_len\n",
    "    else:\n",
    "        total_len = len(g)\n",
    "        for idx in range(len(r)):\n",
    "            if r[idx] in g:\n",
    "                score += 1\n",
    "        acc = (score / total_len ) * 100\n",
    "        all_score += score\n",
    "        all_total_length += total_len\n",
    "        \n",
    "    # display image\n",
    "    img = d[0]['image_input'][i][:,:,0].T\n",
    "    plt.figure(figsize=[10,1.03])\n",
    "    plt.imshow(img, cmap='gray', interpolation=None)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.text(0, 45, '%s' % (''.join(chars)) )\n",
    "    plt.text(0, 60, 'GT: %-24s RT: %-24s %0.2f   %0.2f' % (gt_str, res_str, ed_norm, acc))\n",
    "    \n",
    "            \n",
    "    \n",
    "    #file_name = 'plots/%s_recogniton_%03d.pgf' % (plot_name, i)\n",
    "    file_name = 'plots/%s_recogniton_%03d.png' % (plot_name, i)\n",
    "    #plt.savefig(file_name, bbox_inches='tight', dpi=300)\n",
    "    #print(file_name)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #print('%-20s %-20s %s %0.2f' % (gt_str, res_str, ''.join(chars), ed_norm))\n",
    "\n",
    "mean_ed /= len(res)\n",
    "mean_ed_norm /= len(res)\n",
    "all_acc = (all_score / all_total_length ) * 100\n",
    "\n",
    "print('\\nmean editdistance: %0.3f\\nmean normalized editdistance: %0.3f\\naccuracy: %0.3f' % (mean_ed, mean_ed_norm, all_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ina",
   "language": "python",
   "name": "ina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
